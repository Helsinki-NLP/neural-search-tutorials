{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural search with averaged word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use the `gensim` toolkit to demonstrate a simple approach to neural search. In a nutshell, we create document vectors for each document by averaging the *GloVe* vectors of each word occurring in the document. We encode the query in the same way and find the most similar documents using cosine similarity. We will work on the *Lee Background Corpus* containing 300 short news items. This corpus is distributed together with `gensim`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install gensim\n",
    "\n",
    "First, we need to install `gensim`. This may take a while.\n",
    "\n",
    "On a command line Python version, install it the usual way: `pip install gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the corpus\n",
    "\n",
    "Let us load the corpus and display the beginnings of the first few news stories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "\n",
    "lee_bg_file = os.path.join(gensim.__path__[0], 'test', 'test_data', 'lee_background.cor')\n",
    "lee_bg_corpus = open(lee_bg_file, 'r')\n",
    "texts = lee_bg_corpus.readlines()\n",
    "lee_bg_corpus.close()\n",
    "for i in range(20):\n",
    "    print(f\"({i:>2})  {texts[i][:100]}...\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word embeddings\n",
    "\n",
    "Now, we need to load the word embeddings. The original *word2vec* embedding file is too large for the CSC notebooks, and we're going to use a *GloVe* embedding file instead. The *GloVe* embeddings are distributed together with this notebook, but you can look at the [gensim-data](https://github.com/RaRe-Technologies/gensim-data) repository for other options.\n",
    "\n",
    "**Attention:** The embedding file will use about 2GB of RAM and loading it will take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('~/shared/glove-wiki-gigaword-200.gz')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute document vectors\n",
    "\n",
    "Next, we need to compute a document vector for each of the 300 news stories. We take one story at a time and do the following:\n",
    "\n",
    "- Remove the stopwords\n",
    "- Further preprocess the data (remove punctuation, lowercase, tokenize)\n",
    "- Compute the average vector of all tokens appearing in the story\n",
    "- Store the average vector in `doc_vectors`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector collection with the same number of dimensions as the word vectors and as many entries as there are texts\n",
    "doc_vectors = gensim.models.keyedvectors.KeyedVectors(word_vectors.vector_size, count=len(texts))\n",
    "\n",
    "for i, line in enumerate(texts):\n",
    "    # gensim provides procedures for preprocessing and stopword removal\n",
    "    text_without_stopwords = gensim.parsing.preprocessing.remove_stopwords(line)\n",
    "    tokens = gensim.utils.simple_preprocess(text_without_stopwords)\n",
    "    # the function get_mean_vector computes the average vector for all tokens\n",
    "    dv = word_vectors.get_mean_vector(tokens)\n",
    "    doc_vectors.add_vector(i, dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the document collection\n",
    "\n",
    "Now we can start writing queries and searching for the most relevant documents.\n",
    "\n",
    "Here are four queries in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Israel\",\n",
    "    \"investors capital profits financial services\",\n",
    "    \"militant terrorist killed\",\n",
    "    \"earthquake flood rain tsunami forest fire\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one query at a time and do the following:\n",
    "\n",
    "- Process it in the same way as the document collection\n",
    "- Compute the average vector for all tokens in the query\n",
    "- Find the 5 most similar documents to the query\n",
    "- Display the similarity score, the document id and the beginning of the document text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in queries:\n",
    "    print(\"Query:\", q)\n",
    "    q_without_stopwords = gensim.parsing.preprocessing.remove_stopwords(q)\n",
    "    q_tokens = gensim.utils.simple_preprocess(q_without_stopwords)\n",
    "    qv = word_vectors.get_mean_vector(q_tokens)\n",
    "    most_similar = doc_vectors.most_similar([qv], topn=5)\n",
    "    for doc_position, doc_score in most_similar:\n",
    "        print(f\"- {doc_score:.4f}  ({doc_position:>3})  {texts[doc_position][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it... What do you think of the results? Feel free to modify the queries and the `topn` value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
